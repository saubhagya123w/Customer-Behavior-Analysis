{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('customers',)\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "# Establish the connection\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    user=\"root\",\n",
    "    password=\"1234qwert\",\n",
    "    database=\"saubhagya12\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SHOW TABLES\")\n",
    "for table in cursor:\n",
    "    print(table)\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUSTOMERS DATA CONNECTION AND ANALYTICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data of Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID      CustomerName                         Email  Gender  Age  \\\n",
      "0           1     Emma Anderson     emma.anderson@example.com    Male   50   \n",
      "1           2       Sarah Brown       sarah.brown@example.com  Female   37   \n",
      "2           3  Robert Hernandez  robert.hernandez@example.com  Female   26   \n",
      "3           4      David Garcia      david.garcia@example.com    Male   25   \n",
      "4           5       Emma Miller       emma.miller@example.com  Female   41   \n",
      "\n",
      "   GeographyID  \n",
      "0            2  \n",
      "1            4  \n",
      "2            6  \n",
      "3            8  \n",
      "4            4  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data1 = pd.read_csv(\"customers.csv\")\n",
    "print(data1.head())  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 6)\n"
     ]
    }
   ],
   "source": [
    "print(data1.shape) # number of rows and columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID       int64\n",
      "CustomerName    object\n",
      "Email           object\n",
      "Gender          object\n",
      "Age              int64\n",
      "GeographyID      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data1.dtypes) # Data Types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count missing values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID      0\n",
      "CustomerName    0\n",
      "Email           0\n",
      "Gender          0\n",
      "Age             0\n",
      "GeographyID     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data1.isnull().sum())  # Count missing values per column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(data1.duplicated().sum())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive Statistics\n",
    "Summary of numerical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       CustomerID         Age  GeographyID\n",
      "count  100.000000  100.000000   100.000000\n",
      "mean    50.500000   41.990000     5.320000\n",
      "std     29.011492   14.259142     2.810083\n",
      "min      1.000000   18.000000     1.000000\n",
      "25%     25.750000   31.000000     3.000000\n",
      "50%     50.500000   41.000000     5.000000\n",
      "75%     75.250000   53.000000     8.000000\n",
      "max    100.000000   69.000000    10.000000\n"
     ]
    }
   ],
   "source": [
    "print(data1.describe())  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         CustomerName                      Email  Gender\n",
      "count             100                        100     100\n",
      "unique            100                        100       2\n",
      "top     Emma Anderson  emma.anderson@example.com  Female\n",
      "freq                1                          1      54\n"
     ]
    }
   ],
   "source": [
    "print(data1.describe(include=[\"object\"]))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected the engagement_data2.csv file with table in MYSQL Workbench i.e\n",
    "create table customers(\n",
    "CustomerID int auto_increment primary key,\n",
    "customerName text,\n",
    "Email text,\n",
    "Gender text,\n",
    "Age int,\n",
    "GeographyID int\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV data successfully inserted into MySQL!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection details\n",
    "USER = \"root\"  \n",
    "PASSWORD = \"1234qwert\"  \n",
    "HOST = \"127.0.0.1\"\n",
    "DATABASE = \"saubhagya12\"\n",
    "\n",
    "# Create SQLAlchemy engine using MySQL Connector\n",
    "engine = create_engine(f\"mysql+mysqlconnector://{USER}:{PASSWORD}@{HOST}/{DATABASE}\")\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"customers.csv\")\n",
    "\n",
    "# Insert the CSV data into MySQL\n",
    "data1.to_sql(\"customers\", con=engine, if_exists=\"append\", index=False, method=\"multi\")\n",
    "\n",
    "print(\"CSV data successfully inserted into MySQL!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data of products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID      CustomerName                         Email  Gender  Age  \\\n",
      "0           1     Emma Anderson     emma.anderson@example.com    Male   50   \n",
      "1           2       Sarah Brown       sarah.brown@example.com  Female   37   \n",
      "2           3  Robert Hernandez  robert.hernandez@example.com  Female   26   \n",
      "3           4      David Garcia      david.garcia@example.com    Male   25   \n",
      "4           5       Emma Miller       emma.miller@example.com  Female   41   \n",
      "\n",
      "   GeographyID  \n",
      "0            2  \n",
      "1            4  \n",
      "2            6  \n",
      "3            8  \n",
      "4            4  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data2 = pd.read_csv(\"products.csv\")\n",
    "print(df.head())  # Display first 5 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 4)\n"
     ]
    }
   ],
   "source": [
    "print(data2.shape)  # (num_rows, num_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductID        int64\n",
      "ProductName     object\n",
      "Category        object\n",
      "Price          float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data2.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count missing values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductID      0\n",
      "ProductName    0\n",
      "Category       0\n",
      "Price          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data2.isnull().sum())  # Count missing values per column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(data2.duplicated().sum())  # Count duplicate rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ProductID       Price\n",
      "count   20.00000   20.000000\n",
      "mean    10.50000  205.405500\n",
      "std      5.91608  149.461816\n",
      "min      1.00000   26.210000\n",
      "25%      5.75000   44.262500\n",
      "50%     10.50000  210.215000\n",
      "75%     15.25000  288.412500\n",
      "max     20.00000  485.320000\n"
     ]
    }
   ],
   "source": [
    "print(data2.describe())  # Summary of numerical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ProductName Category\n",
      "count              20       20\n",
      "unique             20        1\n",
      "top     Running Shoes   Sports\n",
      "freq                1       20\n"
     ]
    }
   ],
   "source": [
    "print(data2.describe(include=[\"object\"]))  # Summary of categorical columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected the products.csv file with table in MYSQL Workbench i.e\n",
    "create table products (\n",
    "ProductID int ,\n",
    "ProductName text,\n",
    "Category text,\n",
    "Price int\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV data successfully inserted into MySQL!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection details\n",
    "USER = \"root\"  \n",
    "PASSWORD = \"1234qwert\"  \n",
    "HOST = \"127.0.0.1\"\n",
    "DATABASE = \"saubhagya12\"\n",
    "\n",
    "# Create SQLAlchemy engine using MySQL Connector\n",
    "engine = create_engine(f\"mysql+mysqlconnector://{USER}:{PASSWORD}@{HOST}/{DATABASE}\")\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"products.csv\")\n",
    "\n",
    "# Insert the CSV data into MySQL\n",
    "df.to_sql(\"products\", con=engine, if_exists=\"append\", index=False, method=\"multi\")\n",
    "\n",
    "print(\"CSV data successfully inserted into MySQL!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating the views and clicks from the column ViewsClicksCombined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EngagementID  ContentID ContentType  Likes EngagementDate  CampaignID  \\\n",
      "0             1         39        Blog    190     2023-08-30           1   \n",
      "1             2         48        Blog    114     2023-03-28          18   \n",
      "2             3         16       video     32     2023-12-08           7   \n",
      "3             4         43       Video     17     2025-01-21          19   \n",
      "4             5         16  newsletter    306     2024-02-21           6   \n",
      "\n",
      "   ProductID  Views  Clicks  \n",
      "0          9   1883     671  \n",
      "1         20   5280     532  \n",
      "2         14   1905     204  \n",
      "3         20   2766     257  \n",
      "4         15   5116    1524  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read CSV file \n",
    "data3 = pd.read_csv(\"engagement_data.csv\")\n",
    "\n",
    "# Split the \"ViewsClicksCombined\" column into two new columns: \"Views\" and \"Clicks\"\n",
    "data3[['Views', 'Clicks']] = data3['ViewsClicksCombined'].str.split('-', expand=True)\n",
    "\n",
    "# Convert the new columns to integers (if needed)\n",
    "data3['Views'] = data3['Views'].astype(int)\n",
    "data3['Clicks'] = data3['Clicks'].astype(int)\n",
    "\n",
    "# Drop the original \"ViewsClicksCombined\" column if not needed\n",
    "data3.drop(columns=['ViewsClicksCombined'], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(data3.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the changes in the new file i.e engagement_data2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved as 'engagement_data2.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read CSV file\n",
    "data3 = pd.read_csv(\"engagement_data.csv\")\n",
    "\n",
    "# Split the \"ViewsClicksCombined\" column into \"Views\" and \"Clicks\"\n",
    "data3[['Views', 'Clicks']] = data3['ViewsClicksCombined'].str.split('-', expand=True)\n",
    "\n",
    "# Convert the new columns to integers\n",
    "data3['Views'] = data3['Views'].astype(int)\n",
    "data3['Clicks'] = data3['Clicks'].astype(int)\n",
    "\n",
    "# Drop the original column\n",
    "data3.drop(columns=['ViewsClicksCombined'], inplace=True)\n",
    "\n",
    "# Save the modified DataFrame into a new file\n",
    "data3.to_csv(\"engagement_data2.csv\", index=False)\n",
    "\n",
    "print(\"File saved as 'engagement_data2.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data of engagement_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EngagementID  ContentID ContentType  Likes EngagementDate  CampaignID  \\\n",
      "0             1         39        Blog    190     2023-08-30           1   \n",
      "1             2         48        Blog    114     2023-03-28          18   \n",
      "2             3         16       video     32     2023-12-08           7   \n",
      "3             4         43       Video     17     2025-01-21          19   \n",
      "4             5         16  newsletter    306     2024-02-21           6   \n",
      "\n",
      "   ProductID  Views  Clicks  \n",
      "0          9   1883     671  \n",
      "1         20   5280     532  \n",
      "2         14   1905     204  \n",
      "3         20   2766     257  \n",
      "4         15   5116    1524  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data3 = pd.read_csv(\"engagement_data2.csv\")\n",
    "print(data3.head())  # Display first 5 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 9)\n"
     ]
    }
   ],
   "source": [
    "print(data3.shape)  # (num_rows, num_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EngagementID       int64\n",
      "ContentID          int64\n",
      "ContentType       object\n",
      "Likes              int64\n",
      "EngagementDate    object\n",
      "CampaignID         int64\n",
      "ProductID          int64\n",
      "Views              int64\n",
      "Clicks             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data3.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count missing values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EngagementID      0\n",
      "ContentID         0\n",
      "ContentType       0\n",
      "Likes             0\n",
      "EngagementDate    0\n",
      "CampaignID        0\n",
      "ProductID         0\n",
      "Views             0\n",
      "Clicks            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data3.isnull().sum())  # Count missing values per column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(data3.duplicated().sum())  # Count duplicate rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       EngagementID   ContentID       Likes  CampaignID  ProductID  \\\n",
      "count    100.000000  100.000000  100.000000  100.000000  100.00000   \n",
      "mean      50.500000   27.040000  104.460000   10.920000   10.88000   \n",
      "std       29.011492   14.298351  175.409617    6.154049    5.92594   \n",
      "min        1.000000    1.000000    0.000000    1.000000    1.00000   \n",
      "25%       25.750000   15.750000    2.750000    6.000000    6.00000   \n",
      "50%       50.500000   29.500000   14.500000   11.500000   11.00000   \n",
      "75%       75.250000   37.250000  119.500000   17.000000   16.00000   \n",
      "max      100.000000   50.000000  840.000000   20.000000   20.00000   \n",
      "\n",
      "             Views       Clicks  \n",
      "count   100.000000   100.000000  \n",
      "mean   2270.450000   469.510000  \n",
      "std    2159.334313   684.038505  \n",
      "min      36.000000     1.000000  \n",
      "25%     594.500000    44.000000  \n",
      "50%    1507.000000   141.500000  \n",
      "75%    3253.250000   549.500000  \n",
      "max    9759.000000  3095.000000  \n"
     ]
    }
   ],
   "source": [
    "print(data3.describe())  # Summary of numerical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ContentType EngagementDate\n",
      "count          100            100\n",
      "unique          12             96\n",
      "top          Video     2024-05-26\n",
      "freq            18              2\n"
     ]
    }
   ],
   "source": [
    "print(data3.describe(include=[\"object\"]))  # Summary of categorical columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected the engagement_data2.csv file with table in MYSQL Workbench i.e\n",
    "create table engagement_data2 (\n",
    "EngagementID int Primary key,\n",
    "ContentID int,\n",
    "ContentType text,\n",
    "Likes int,\n",
    "EngagementDate datetime, \n",
    "CampaignID int,\n",
    "ProductID int,\n",
    "Views int,\n",
    "Clicks int\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV data successfully inserted into MySQL!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection details\n",
    "USER = \"root\"  \n",
    "PASSWORD = \"1234qwert\"  \n",
    "HOST = \"127.0.0.1\"\n",
    "DATABASE = \"saubhagya12\"\n",
    "\n",
    "# Create SQLAlchemy engine using MySQL Connector\n",
    "engine = create_engine(f\"mysql+mysqlconnector://{USER}:{PASSWORD}@{HOST}/{DATABASE}\")\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"engagement_data2.csv\")\n",
    "\n",
    "# Insert the CSV data into MySQL\n",
    "df.to_sql(\"engagement_data2\", con=engine, if_exists=\"append\", index=False, method=\"multi\")\n",
    "\n",
    "print(\"CSV data successfully inserted into MySQL!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data of geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   GeographyID  Country    City\n",
      "0            1       UK  London\n",
      "1            2  Germany  Berlin\n",
      "2            3   France   Paris\n",
      "3            4    Spain  Madrid\n",
      "4            5    Italy    Rome\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data4 = pd.read_csv(\"geography.csv\")\n",
    "print(data4.head())  # Display first 5 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data4.shape)  # (num_rows, num_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeographyID     int64\n",
      "Country        object\n",
      "City           object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data4.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count missing values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeographyID    0\n",
      "Country        0\n",
      "City           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data4.isnull().sum())  # Count missing values per column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(data4.duplicated().sum())  # Count duplicate rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       GeographyID\n",
      "count     10.00000\n",
      "mean       5.50000\n",
      "std        3.02765\n",
      "min        1.00000\n",
      "25%        3.25000\n",
      "50%        5.50000\n",
      "75%        7.75000\n",
      "max       10.00000\n"
     ]
    }
   ],
   "source": [
    "print(data4.describe())  # Summary of numerical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Country    City\n",
      "count       10      10\n",
      "unique      10      10\n",
      "top         UK  London\n",
      "freq         1       1\n"
     ]
    }
   ],
   "source": [
    "print(data4.describe(include=[\"object\"]))  # Summary of categorical columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected the geography.csv file with table in MYSQL Workbench i.e\n",
    "create table geography (\n",
    "GeographyID int primary key,\n",
    "Country text,\n",
    "City text\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV data successfully inserted into MySQL!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection details\n",
    "USER = \"root\"  \n",
    "PASSWORD = \"1234qwert\" \n",
    "HOST = \"127.0.0.1\"\n",
    "DATABASE = \"saubhagya12\"\n",
    "\n",
    "# Create SQLAlchemy engine using MySQL Connector\n",
    "engine = create_engine(f\"mysql+mysqlconnector://{USER}:{PASSWORD}@{HOST}/{DATABASE}\")\n",
    "\n",
    "# Read the CSV file\n",
    "data4 = pd.read_csv(\"geography.csv\")\n",
    "\n",
    "# Insert the CSV data into MySQL\n",
    "data4.to_sql(\"geography\", con=engine, if_exists=\"append\", index=False, method=\"multi\")\n",
    "\n",
    "print(\"CSV data successfully inserted into MySQL!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data of customer_journey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   JourneyID  CustomerID  ProductID   VisitDate        Stage    Action  \\\n",
      "0          1          64         18  2024-06-10     Checkout  Drop-off   \n",
      "1          2          94         11  2025-07-09     Checkout  Drop-off   \n",
      "2          3          34          8  2024-06-14  ProductPage      View   \n",
      "3          4          33         18  2025-05-28     Checkout  Drop-off   \n",
      "4          5          91         10  2023-02-11     Homepage     Click   \n",
      "\n",
      "   Duration  \n",
      "0       NaN  \n",
      "1       NaN  \n",
      "2     235.0  \n",
      "3       NaN  \n",
      "4     156.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data5 = pd.read_csv(\"customer_journey.csv\")\n",
    "print(data5.head())  # Display first 5 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 7)\n"
     ]
    }
   ],
   "source": [
    "print(data5.shape)  # (num_rows, num_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JourneyID       int64\n",
      "CustomerID      int64\n",
      "ProductID       int64\n",
      "VisitDate      object\n",
      "Stage          object\n",
      "Action         object\n",
      "Duration      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data5.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count missing values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JourneyID     0\n",
      "CustomerID    0\n",
      "ProductID     0\n",
      "VisitDate     0\n",
      "Stage         0\n",
      "Action        0\n",
      "Duration      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data5.isnull().sum())  # Count missing values per column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replaced missing values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(data5.duplicated().sum())  # Count duplicate rows\n",
    "data5.drop_duplicates(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        JourneyID  CustomerID   ProductID    Duration\n",
      "count  100.000000  100.000000  100.000000  100.000000\n",
      "mean    50.500000   51.090000   11.000000  143.220000\n",
      "std     29.011492   29.383255    6.095204   97.476087\n",
      "min      1.000000    1.000000    1.000000    0.000000\n",
      "25%     25.750000   24.750000    6.000000   47.500000\n",
      "50%     50.500000   52.000000   11.000000  157.000000\n",
      "75%     75.250000   77.250000   16.250000  234.250000\n",
      "max    100.000000   99.000000   20.000000  298.000000\n"
     ]
    }
   ],
   "source": [
    "print(data5.describe())  # Summary of numerical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         VisitDate     Stage Action\n",
      "count          100       100    100\n",
      "unique          97         6      4\n",
      "top     2023-08-22  Homepage   View\n",
      "freq             2        50     58\n"
     ]
    }
   ],
   "source": [
    "print(data5.describe(include=[\"object\"]))  # Summary of categorical columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connection with database in MYSQL Workbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV data successfully inserted into MySQL!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection details\n",
    "USER = \"root\"  \n",
    "PASSWORD = \"1234qwert\"  \n",
    "HOST = \"127.0.0.1\"\n",
    "DATABASE = \"saubhagya12\"\n",
    "\n",
    "# Create SQLAlchemy engine using MySQL Connector\n",
    "engine = create_engine(f\"mysql+mysqlconnector://{USER}:{PASSWORD}@{HOST}/{DATABASE}\")\n",
    "\n",
    "# Read the CSV file\n",
    "data5 = pd.read_csv(\"customer_journey.csv\")\n",
    "\n",
    "# Insert the CSV data into MySQL\n",
    "data5.to_sql(\"customer_journey\", con=engine, if_exists=\"append\", index=False, method=\"multi\")\n",
    "\n",
    "print(\"CSV data successfully inserted into MySQL!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data of customer_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ReviewID  CustomerID  ProductID  ReviewDate  Rating  \\\n",
      "0         1          77         18  2023-12-23       3   \n",
      "1         2          80         19  2024-12-25       5   \n",
      "2         3          50         13  2025-01-26       4   \n",
      "3         4          78         15  2025-04-21       3   \n",
      "4         5          64          2  2023-07-16       3   \n",
      "\n",
      "                                 ReviewText  \n",
      "0   Average  experience,  nothing  special.  \n",
      "1            The  quality  is    top-notch.  \n",
      "2   Five  stars  for  the  quick  delivery.  \n",
      "3  Good  quality,  but  could  be  cheaper.  \n",
      "4   Average  experience,  nothing  special.  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data6 = pd.read_csv(\"customer_reviews.csv\")\n",
    "print(data6.head())  # Display first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 6)\n"
     ]
    }
   ],
   "source": [
    "print(data6.shape)  # (num_rows, num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReviewID       int64\n",
      "CustomerID     int64\n",
      "ProductID      int64\n",
      "ReviewDate    object\n",
      "Rating         int64\n",
      "ReviewText    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data6.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count missing values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReviewID      0\n",
      "CustomerID    0\n",
      "ProductID     0\n",
      "ReviewDate    0\n",
      "Rating        0\n",
      "ReviewText    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data6.isnull().sum())  # Count missing values per column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(data6.duplicated().sum())  # Count duplicate rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ReviewID  CustomerID   ProductID      Rating\n",
      "count  100.000000  100.000000  100.000000  100.000000\n",
      "mean    50.500000   53.850000   10.450000    3.730000\n",
      "std     29.011492   29.685345    5.815992    0.983243\n",
      "min      1.000000    2.000000    1.000000    1.000000\n",
      "25%     25.750000   29.000000    5.000000    3.000000\n",
      "50%     50.500000   55.500000   11.000000    4.000000\n",
      "75%     75.250000   78.000000   16.000000    4.000000\n",
      "max    100.000000  100.000000   20.000000    5.000000\n"
     ]
    }
   ],
   "source": [
    "print(data6.describe())  # Summary of numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ReviewDate                               ReviewText\n",
      "count          100                                      100\n",
      "unique          96                                       38\n",
      "top     2023-07-17  Five  stars  for  the  quick  delivery.\n",
      "freq             2                                       15\n"
     ]
    }
   ],
   "source": [
    "print(data6.describe(include=[\"object\"]))  # Summary of categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected the customer_reviews.csv file with table in MYSQL Workbench i.e\n",
    "create table customer_reviews (\n",
    "ReviewID int primary key,\n",
    "CustomerID int,\n",
    "ProductID int,\n",
    "ReviewDate datetime,\n",
    "Rating int,\n",
    "ReviewText text\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV data successfully inserted into MySQL!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection details\n",
    "USER = \"root\"  \n",
    "PASSWORD = \"1234qwert\"  \n",
    "HOST = \"127.0.0.1\"\n",
    "DATABASE = \"saubhagya12\"\n",
    "\n",
    "# Create SQLAlchemy engine using MySQL Connector\n",
    "engine = create_engine(f\"mysql+mysqlconnector://{USER}:{PASSWORD}@{HOST}/{DATABASE}\")\n",
    "\n",
    "# Read the CSV file\n",
    "data6 = pd.read_csv(\"customer_reviews.csv\")\n",
    "\n",
    "# Insert the CSV data into MySQL\n",
    "data6.to_sql(\"customer_reviews\", con=engine, if_exists=\"append\", index=False, method=\"multi\")\n",
    "\n",
    "print(\"CSV data successfully inserted into MySQL!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SENTIMENT ANALYSIS OF customer_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment_Label\n",
      "Neutral     69\n",
      "Positive    30\n",
      "Negative     1\n",
      "Name: count, dtype: int64\n",
      "                                 ReviewText Sentiment_Label\n",
      "0   Average  experience,  nothing  special.         Neutral\n",
      "1            The  quality  is    top-notch.         Neutral\n",
      "2   Five  stars  for  the  quick  delivery.         Neutral\n",
      "3  Good  quality,  but  could  be  cheaper.        Positive\n",
      "4   Average  experience,  nothing  special.         Neutral\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load customer reviews data\n",
    "df = pd.read_csv(\"customer_reviews.csv\") \n",
    "# Define simple positive and negative words\n",
    "positive_words = [\"good\", \"great\", \"excellent\", \"amazing\", \"love\", \"best\", \"happy\", \"positive\", \"satisfied\"]\n",
    "negative_words = [\"bad\", \"poor\", \"worst\", \"terrible\", \"awful\", \"hate\", \"negative\", \"unsatisfied\"]\n",
    "# Function to assign sentiment based on keyword matching\n",
    "def simple_sentiment(text):\n",
    "    text = str(text).lower()  # Convert to lowercase\n",
    "    if any(word in text for word in positive_words):\n",
    "        return \"Positive\"\n",
    "    elif any(word in text for word in negative_words):\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "df['Sentiment_Label'] = df['ReviewText'].apply(simple_sentiment)\n",
    "print(df['Sentiment_Label'].value_counts())\n",
    "print(df[['ReviewText', 'Sentiment_Label']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stored the sentimental analysis data into new csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis completed! Results saved to 'sentiment_analysis.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load customer reviews data\n",
    "df = pd.read_csv(\"customer_reviews.csv\") \n",
    "positive_words = [\"good\", \"great\", \"excellent\", \"amazing\", \"love\", \"best\", \"happy\", \"positive\", \"satisfied\"]\n",
    "negative_words = [\"bad\", \"poor\", \"worst\", \"terrible\", \"awful\", \"hate\", \"negative\", \"unsatisfied\"]\n",
    "def simple_sentiment(text):\n",
    "    text = str(text).lower()\n",
    "    if any(word in text for word in positive_words):\n",
    "        return \"Positive\"\n",
    "    elif any(word in text for word in negative_words):\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "df['Sentiment_Label'] = df['ReviewText'].apply(simple_sentiment)\n",
    "# Save results to a new CSV file\n",
    "df.to_csv(\"sentiment_analysis.csv\", index=False)\n",
    "print(\"Sentiment analysis completed! Results saved to 'sentiment_analysis.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data of Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ReviewID  CustomerID  ProductID  ReviewDate  Rating  \\\n",
      "0         1          77         18  2023-12-23       3   \n",
      "1         2          80         19  2024-12-25       5   \n",
      "2         3          50         13  2025-01-26       4   \n",
      "3         4          78         15  2025-04-21       3   \n",
      "4         5          64          2  2023-07-16       3   \n",
      "\n",
      "                                 ReviewText Sentiment_Label  \n",
      "0   Average  experience,  nothing  special.         Neutral  \n",
      "1            The  quality  is    top-notch.         Neutral  \n",
      "2   Five  stars  for  the  quick  delivery.         Neutral  \n",
      "3  Good  quality,  but  could  be  cheaper.        Positive  \n",
      "4   Average  experience,  nothing  special.         Neutral  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"sentiment_analysis.csv\")\n",
    "print(df.head())  # Display first 5 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 7)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)  # (num_rows, num_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReviewID            int64\n",
      "CustomerID          int64\n",
      "ProductID           int64\n",
      "ReviewDate         object\n",
      "Rating              int64\n",
      "ReviewText         object\n",
      "Sentiment_Label    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count missing values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReviewID           0\n",
      "CustomerID         0\n",
      "ProductID          0\n",
      "ReviewDate         0\n",
      "Rating             0\n",
      "ReviewText         0\n",
      "Sentiment_Label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())  # Count missing values per column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().sum())  # Count duplicate rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ReviewID  CustomerID   ProductID      Rating\n",
      "count  100.000000  100.000000  100.000000  100.000000\n",
      "mean    50.500000   53.850000   10.450000    3.730000\n",
      "std     29.011492   29.685345    5.815992    0.983243\n",
      "min      1.000000    2.000000    1.000000    1.000000\n",
      "25%     25.750000   29.000000    5.000000    3.000000\n",
      "50%     50.500000   55.500000   11.000000    4.000000\n",
      "75%     75.250000   78.000000   16.000000    4.000000\n",
      "max    100.000000  100.000000   20.000000    5.000000\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())  # Summary of numerical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ReviewDate                               ReviewText Sentiment_Label\n",
      "count          100                                      100             100\n",
      "unique          96                                       38               3\n",
      "top     2023-07-17  Five  stars  for  the  quick  delivery.         Neutral\n",
      "freq             2                                       15              69\n"
     ]
    }
   ],
   "source": [
    "print(df.describe(include=[\"object\"]))  # Summary of categorical columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected the sentiment_analysis.csv file with table in MYSQL Workbench i.e\n",
    "CREATE TABLE sentiment_analysis (\n",
    "    ReviewID INT PRIMARY KEY,\n",
    "    CustomerID INT,\n",
    "    ProductID INT,\n",
    "    ReviewDate DATETIME,\n",
    "    Rating INT,\n",
    "    ReviewText TEXT,\n",
    "    Sentiment_Label TEXT\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV data successfully inserted into MySQL!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection details\n",
    "USER = \"root\"  \n",
    "PASSWORD = \"1234qwert\" \n",
    "HOST = \"127.0.0.1\"\n",
    "DATABASE = \"saubhagya12\"\n",
    "\n",
    "# Create SQLAlchemy engine using MySQL Connector\n",
    "engine = create_engine(f\"mysql+mysqlconnector://{USER}:{PASSWORD}@{HOST}/{DATABASE}\")\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"sentiment_analysis.csv\")\n",
    "\n",
    "# Insert the CSV data into MySQL\n",
    "df.to_sql(\"sentiment_analysis\", con=engine, if_exists=\"append\", index=False, method=\"multi\")\n",
    "\n",
    "print(\"CSV data successfully inserted into MySQL!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
